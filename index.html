<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion via Training-Free Guidance">
  <meta property="og:title" content="WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion via Training-Free Guidance"/>
  <meta property="og:description" content="Research on emergent 3D/4D generation in video diffusion models"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion">
  <meta name="twitter:description" content="Research on emergent 3D/4D generation in video diffusion models">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="video diffusion, 3D generation, 4D generation, training-free guidance, WorldForge, AGI">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion via Training-Free Guidance</title>
  <link rel="icon" type="image/x-icon" href="static/images/worldforge.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro|Montserrat:400,700,900|Varela+Round|Quicksand:400,700|Nunito:400,700,900|Poppins:400,700,900"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <style>
    .gradient-text {
      font-weight: 900;
      background: linear-gradient(90deg, #6a11cb 0%, #2575fc 100%);
      -webkit-background-clip: text;
      background-clip: text;
      -webkit-text-fill-color: transparent;
      display: inline;
      text-shadow: 3px 3px 1px rgba(0, 0, 0, 0.1);
      /* -webkit-text-stroke: 0.5px rgba(106, 17, 203, 0.1);  */
      font-size: 4rem;
      font-family: 'Noto Sans', sans-serif;
    }
    
    .logo-image {
      width: 80px;
      height: 80px;
      vertical-align: middle;
      margin-right: 10px;
    }
    
    .publication-title h1 {
      margin-bottom: 0.5rem;
      font-size: 3.5rem;
    }
    
    .publication-title h2 {
      margin-top: 0.5rem;
      line-height: 1.4;
      font-size: 2.2rem;
    }
    
    .hero.teaser video {
      width: 90%;
      height: auto;
      min-height: 500px;
      max-height: 700px;
      object-fit: contain;
      display: block;
      margin: 0 auto;
    }
    
    .blue-purple-gradient {
      font-weight: bold;
      background: linear-gradient(180deg, #4285f4 0%, #9c27b0 100%);
      -webkit-background-clip: text;
      background-clip: text;
      -webkit-text-fill-color: transparent;
      display: inline;
    }
    
    .pink-orange-gradient {
      font-weight: bold;
      background: linear-gradient(180deg, #ff6b9d 0%, #ff8a50 100%);
      -webkit-background-clip: text;
      background-clip: text;
      -webkit-text-fill-color: transparent;
      display: inline;
    }
    
    .green-blue-purple-gradient {
      font-weight: bold;
      background: linear-gradient(180deg, #00c851 0%, #007bff 50%, #9c27b0 100%);
      -webkit-background-clip: text;
      background-clip: text;
      -webkit-text-fill-color: transparent;
      display: inline;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="publication-title">
              <h1 class="title is-1"><img src="static/images/worldforge.png" alt="WorldForge Logo" class="logo-image"><span class="gradient-text">WorldForge</span></h1>
              <h2 class="title is-2"><span style="font-weight: 600;">Unlocking Emergent 3D/4D Generation in<br>Video Diffusion Model via Training-Free Guidance</span></h2>
            </div>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <!-- <a href="https://chenxi-song.github.io" target="_blank">Chenxi Song</a><sup>1</sup>,</span> -->
                <a href="https://worldforge-agi.github.io" target="_blank">Chenxi Song</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://2hiTee.github.io" target="_blank">Yanming Yang</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://tongzhao1030.github.io" target="_blank">Tong Zhao</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=qtGY5T4AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Ruibo Li</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://icoz69.github.io" target="_blank">Chi Zhang</a><sup>1*</sup>
                  </span>
                  </div>

                  <div class="is-size-6 publication-authors">
                    <span class="author-block"><strong><sup>1</sup>AGI Lab, Westlake University</strong>   <strong><sup>2</sup>   The College of Computing and Data Science, Nanyang Technological University</strong><br> Email: {songchenxi, yangyanming, zhaotong68, chizhang}@westlake.edu.cn, ruibo001@e.ntu.edu.sg</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span> -->
                  </div>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Westlake-AGI-Lab/WorldForge" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (<strong>Coming very soon</strong>)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2509.15130" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop width="100%" height="auto" style="max-height: 900px;">
        <!-- Your video here -->
        <source src="static/videos/Page_office_30fps.mp4" 
        type="video/mp4">
      </video>
        <h2 class="subtitle has-text-centered">
         We propose <span class="gradient-text" style="font-size: inherit;">WorldForge</span>,a training-free framework that unlocks the world-modeling potential of video diffusion models, <br>delivering controllable 3D/4D generation with unprecedented realism.
        </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered" style="font-weight: 900;">More Details</h2>
      
      <div class="content has-text-justified" style="margin: 2rem 0;">
        <p style="font-size: 1.0rem; margin-bottom: 1.5rem;">
          We showcase more interesting cases to demonstrate the capabilities of our project. For <span class="blue-purple-gradient" style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">3D scene generation</span>, we include voyager experiences in non-realistic scenes such as <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">Artworks</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">AIGC</strong> content, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">portrait photography</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">city walks</strong>, and more. For <span class="pink-orange-gradient" style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">4D video re-cam</span>, we demonstrate camera <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">arc rotation</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">local close-ups</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">outpainting</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">viewpoint transferring</strong>, and <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">video stabilization</strong>. Additionally, we perform <span class="green-blue-purple-gradient" style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">video editing</span> tasks including <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">object removal</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">object addition</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">face swapping</strong>, <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">subject transformation</strong>, and <strong style="text-shadow: 0.5px 0.5px 0.5px rgba(0, 0, 0, 0.3);">try-on</strong> applications. 
           </p>
      </div>
      
      <!-- Original carousel code (commented out for future use)
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      -->
      
      <!-- Video Grid Layout (5x2) -->
      <div class="video-grid" style="display: flex; flex-direction: column; gap: 1.5rem; margin: 2rem 0;">
        <!-- Row 1 -->
        <div class="video-row" style="display: flex; gap: 1.5rem;">
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case1_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case2_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
        
        <!-- Row 2 -->
        <div class="video-row" style="display: flex; gap: 1.5rem;">
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case3_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case4_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
        
        <!-- Row 3 -->
        <div class="video-row" style="display: flex; gap: 1.5rem;">
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case5_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case6_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
        
        <!-- Row 4 -->
        <div class="video-row" style="display: flex; gap: 1.5rem;">
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case7_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case8_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
        
        <!-- Row 5 -->
        <div class="video-row" style="display: flex; gap: 1.5rem;">
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case9_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <div class="video-item" style="flex: 1;">
            <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 400px;">
              <source src="static/videos/case10_fps30.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent video diffusion models demonstrate strong potential in spatial intelligence tasks due to their rich latent world priors. However, their lack of controllability and geometric consistency often necessitates retraining or fine-tuning for 3D/4D tasks, which risks degrading pretrained knowledge and incurs high computational costs. To resolve the tension between generalization and controllability, we propose WorldForge, a <em>training-free, inference-time</em> framework composed of three tightly coupled modules. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">Intra-Step Recursive Refinement (IRR)</strong> introduces a predict–correct loop within each denoising step, creating injection points for trajectory control. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">Flow-Gated Latent Fusion (FLF)</strong> decouples motion from appearance via optical flow similarity, enabling precise and localized control signal injection. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">Dual-Path Self-Corrective Guidance (DSG)</strong> compares guided and unguided denoising paths to adaptively correct trajectory drift caused by structural noise. Together, these components inject fine-grained, trajectory-aligned guidance without retraining, achieving both accurate motion control and photorealistic content generation. Extensive experiments across diverse benchmarks validate our method's superiority in realism, trajectory consistency, and visual fidelity. This work introduces a novel plug-and-play paradigm for controllable video synthesis, offering a new perspective on leveraging generative priors for spatial intelligence.         </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method section -->
<section class="section">
  <!-- <div class="container is-max-desktop"> -->
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <!-- <h2 class="title is-3 has-text-centered" style="font-weight: 900;">Method</h2> -->
        <div class="content has-text-justified">
          
          <p>
            We propose a general <em>inference-time guidance</em> paradigm that leverages the rich priors of large-scale VDMs in spatial intelligence tasks, such as geometry-aware 3D scene generation and video trajectory control. Our method adopts a warping-and-repainting pipeline, in which input frames are warped along a reference trajectory and then used as conditional inputs in the repainting stage. Building on this, we develop a <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">unified, training-free</strong> framework composed of three complementary mechanisms, each designed to address a specific challenge in trajectory-controlled generation.
          </p>
        </div>
        
        <!-- Method figure -->
        <div class="method-figure" style="margin: 2rem 0; text-align: center;">
          <img src="static/images/pipeline3.png" alt="Method Pipeline" style="width: 100%; height: auto; max-width: 100%;">
        </div>
        
        <div class="content has-text-justified">
          <p style="font-size: 1rem; color: #666; margin-top: 1rem;">
            Given a single image or video frames, a vision foundation model reconstructs a scene point cloud, which is warped and rendered along a user-specified trajectory to produce a guidance video. The input image (or first frame) is also converted into a textual prompt and latent representation for an image-to-video diffusion model. Trajectory control is injected through a training-free strategy comprising IRR, FLF, and DSG (detailed in Sec.~3.2–3.4), enabling precise control and high-quality synthesis without additional training.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End method section -->


<!-- Comparisons section -->
<section class="section hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3" style="font-weight: 900;">Comparisons</h2>
        
        <div class="content has-text-justified" style="margin: 1rem 0;">
          <p style="font-size: 1.0rem; margin-bottom: 1.0rem;">
            <span class="blue-purple-gradient" style="font-size: 1.0rem; text-shadow: 1.1px 1.1px 0.9px rgba(0, 0, 0, 0.3); font-weight: bold;">3D Scene Generation</span> <strong>from</strong> <strong style="font-size: 1.0rem; text-shadow: 1.1px 1.1px 0.9px rgba(0, 0, 0, 0.3);">Single</strong> <strong>View</strong>: Compared to existing SOTA methods, our approach produces more consistent scene content under novel viewpoints, with improved image detail, trajectory accuracy, and structural plausibility.
          </p>
          
          <p style="font-size: 1.0rem; margin-bottom: 1.0rem;">
            <strong>Dynamic</strong> <span class="pink-orange-gradient" style="font-size: 1.0rem; text-shadow: 1.1px 1.1px 0.9px rgba(0, 0, 0, 0.3); font-weight: bold;">4D Video Re-Cam</span>: Comparison of 4D trajectory-controlled re-rendering. Baselines often produce implausible artifacts (e.g., flattened faces, floating heads), reflecting limited use of pretrained priors. Our inference-time guidance leverages these latent world priors to re-render realistic, high-quality content along the target trajectory. We compare against state-of-the-art baselines under identical inputs; for ReCamMaster (text-controlled), parameters are adjusted to match the target path.
          </p>
        </div>
        
        <div class="video-container" style="margin: 1.2rem 0;">
          <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 900px;">
            <!-- Comparison video -->
            <source src="static/videos/Comparison_web_30fps.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End comparisons section -->


<!-- Ablation Experiments section -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3" style="font-weight: 900;">Ablation Experiments</h2>
        
        <div class="content has-text-justified">
          <p style="font-size: 1.0rem; margin-bottom: 1.5rem;">
            Ablation of the proposed components. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">IRR</strong> enables trajectory injection; without it, the model defaults to prompt-only free generation, and <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">FLF/DSG</strong> cannot be applied. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">FLF</strong> decouples trajectory cues from noisy content; removing it introduces noise from warped frames. <strong style="text-shadow: 0.8px 0.8px 0.8px rgba(0, 0, 0, 0.3);">DSG</strong> guides sampling toward high-quality, trajectory-consistent results; without it, detail and plausibility drop. The full model achieves the best fidelity and control, demonstrating their complementary effects.
          </p>
        </div>
        
        <div class="video-container" style="margin: 1.5rem 0;">
          <video poster="" autoplay controls muted loop width="100%" height="auto" style="max-height: 800px;">
            <!-- Ablation experiments video -->
            <source src="static/videos/Ablation_web_30fps.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End ablation experiments section -->









<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{song2025worldforgeunlockingemergent3d4d,
        title={WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance}, 
        author={Chenxi Song and Yanming Yang and Tong Zhao and Ruibo Li and Chi Zhang},
        year={2025},
        url={https://arxiv.org/abs/2509.15130}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
